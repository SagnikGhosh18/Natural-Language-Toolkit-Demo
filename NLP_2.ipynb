{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'and': 8, 'unstructured': 6, 'of': 5, 'data': 4, 'by': 4, 'can': 3, 'are': 3, 'for': 3, 'such': 3, 'as': 3, ...})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Frequency Distribution (Output is a dictionary)\n",
    "#Sorted in decreasing frequency\n",
    "\n",
    "text1 = 'Simple content searches can be performed on textual unstructured data. Traditional analytics tools are optimized for highly structured relational data, so they’re of little use for unstructured sources such as rich media, customer interactions, and social media data. Big Data and unstructured data often go together: IDC estimates that 90% of these extremely large datasets are unstructured. New tools have recently become available to analyze these and other unstructured sources. Powered by AI and machine learning, such platforms function at near real-time speed and educate themselves based on the patterns and insights they uncover.Unstructured types of data can actually have internal structural elements. They’re considered “unstructured” because their information doesn’t lend itself to the kind of table formatting required by a relational database. As noted earlier, unstructured data can be textual or non-textual (such as audio, video, and images), and generated by people or by machines. Non-relational databases such as MongoDB are the preferred choice for storing many kinds of unstructured data'\n",
    "fd = nltk.FreqDist(text1.split())\n",
    "fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import ConditionalFreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'data': 4, 'such': 3, 'have': 2, 'rich': 1, 'Data': 1, 'that': 1, 'near': 1, 'they': 1, 'lend': 1, 'kind': 1, ...})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cfd[n] returns n letter words and their frequency\n",
    "\n",
    "cfd = ConditionalFreqDist((len(word),word) for word in text1.split())\n",
    "cfd[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determine FD and the CFD of any one of the Presidential inaugural addresses\n",
    "\n",
    "from nltk.corpus import inaugural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'the': 240, ',': 195, 'of': 146, 'to': 132, '.': 110, 'and': 101, 'be': 76, 'in': 72, 'that': 57, 'a': 53, ...})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2 = inaugural.words('1861-Lincoln.txt')\n",
    "fd1 = nltk.FreqDist(text2)\n",
    "fd1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'present': 5, 'purpose': 5, 'section': 5, 'service': 5, 'slavery': 4, 'plainly': 4, 'written': 4, 'perfect': 4, 'between': 4, 'another': 3, ...})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfd1 = ConditionalFreqDist((len(word),word) for word in text2)\n",
    "cfd1[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache C:\\Users\\HP\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.671 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "绝对 不是 。\n"
     ]
    }
   ],
   "source": [
    "#JIEBA is a package which \n",
    "#Chinese segmentation using Jieba\n",
    "# Uses forward matching algorithm which returns the longest legal dictionary word in the string. Then the next word is processed.\n",
    "import jieba\n",
    "chineseText = \"绝对不是。\"\n",
    "seg = jieba.cut(chineseText, cut_all=True)\n",
    "print(\" \".join(seg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Become', 'an', 'expert', 'in', 'NLP']\n"
     ]
    }
   ],
   "source": [
    "#Basic text processing pipeline\n",
    "\n",
    "import nltk\n",
    "sent = \"Become an expert in NLP\"\n",
    "words = nltk.word_tokenize(sent) # basically splitting\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Simple', 'JJ'), ('content', 'JJ'), ('searches', 'NNS'), ('can', 'MD'), ('be', 'VB'), ('performed', 'VBN'), ('on', 'IN'), ('textual', 'JJ'), ('unstructured', 'JJ'), ('data', 'NNS'), ('.', '.')]\n",
      "[('Traditional', 'JJ'), ('analytics', 'NNS'), ('tools', 'NNS'), ('are', 'VBP'), ('optimized', 'VBN'), ('for', 'IN'), ('highly', 'RB'), ('structured', 'VBN'), ('relational', 'JJ'), ('data', 'NNS'), (',', ','), ('so', 'IN'), ('they', 'PRP'), ('’', 'VBP'), ('re', 'NNS'), ('of', 'IN'), ('little', 'JJ'), ('use', 'NN'), ('for', 'IN'), ('unstructured', 'JJ'), ('sources', 'NNS'), ('such', 'JJ'), ('as', 'IN'), ('rich', 'JJ'), ('media', 'NNS'), (',', ','), ('customer', 'NN'), ('interactions', 'NNS'), (',', ','), ('and', 'CC'), ('social', 'JJ'), ('media', 'NNS'), ('data', 'NNS'), ('.', '.')]\n",
      "[('Big', 'NNP'), ('Data', 'NNP'), ('and', 'CC'), ('unstructured', 'JJ'), ('data', 'NNS'), ('often', 'RB'), ('go', 'VBP'), ('together', 'RB'), (':', ':'), ('IDC', 'NNP'), ('estimates', 'VBZ'), ('that', 'IN'), ('90', 'CD'), ('%', 'NN'), ('of', 'IN'), ('these', 'DT'), ('extremely', 'RB'), ('large', 'JJ'), ('datasets', 'NNS'), ('are', 'VBP'), ('unstructured', 'JJ'), ('.', '.')]\n",
      "[('New', 'NNP'), ('tools', 'NNS'), ('have', 'VBP'), ('recently', 'RB'), ('become', 'VBN'), ('available', 'JJ'), ('to', 'TO'), ('analyze', 'VB'), ('these', 'DT'), ('and', 'CC'), ('other', 'JJ'), ('unstructured', 'JJ'), ('sources', 'NNS'), ('.', '.')]\n",
      "[('Powered', 'VBN'), ('by', 'IN'), ('AI', 'NNP'), ('and', 'CC'), ('machine', 'NN'), ('learning', 'NN'), (',', ','), ('such', 'JJ'), ('platforms', 'NNS'), ('function', 'VBP'), ('at', 'IN'), ('near', 'IN'), ('real-time', 'JJ'), ('speed', 'NN'), ('and', 'CC'), ('educate', 'VBP'), ('themselves', 'PRP'), ('based', 'VBN'), ('on', 'IN'), ('the', 'DT'), ('patterns', 'NNS'), ('and', 'CC'), ('insights', 'NNS'), ('they', 'PRP'), ('uncover.Unstructured', 'VBD'), ('types', 'NNS'), ('of', 'IN'), ('data', 'NNS'), ('can', 'MD'), ('actually', 'RB'), ('have', 'VB'), ('internal', 'JJ'), ('structural', 'JJ'), ('elements', 'NNS'), ('.', '.')]\n",
      "[('They', 'PRP'), ('’', 'VBP'), ('re', 'NNS'), ('considered', 'VBN'), ('“', 'RB'), ('unstructured', 'JJ'), ('”', 'NNS'), ('because', 'IN'), ('their', 'PRP$'), ('information', 'NN'), ('doesn', 'NN'), ('’', 'NNP'), ('t', 'NN'), ('lend', 'VBP'), ('itself', 'PRP'), ('to', 'TO'), ('the', 'DT'), ('kind', 'NN'), ('of', 'IN'), ('table', 'JJ'), ('formatting', 'NN'), ('required', 'VBN'), ('by', 'IN'), ('a', 'DT'), ('relational', 'JJ'), ('database', 'NN'), ('.', '.')]\n",
      "[('As', 'IN'), ('noted', 'VBN'), ('earlier', 'RBR'), (',', ','), ('unstructured', 'JJ'), ('data', 'NNS'), ('can', 'MD'), ('be', 'VB'), ('textual', 'JJ'), ('or', 'CC'), ('non-textual', 'JJ'), ('(', '('), ('such', 'JJ'), ('as', 'IN'), ('audio', 'NN'), (',', ','), ('video', 'NN'), (',', ','), ('and', 'CC'), ('images', 'NNS'), (')', ')'), (',', ','), ('and', 'CC'), ('generated', 'VBN'), ('by', 'IN'), ('people', 'NNS'), ('or', 'CC'), ('by', 'IN'), ('machines', 'NNS'), ('.', '.')]\n",
      "[('Non-relational', 'JJ'), ('databases', 'NNS'), ('such', 'JJ'), ('as', 'IN'), ('MongoDB', 'NNP'), ('are', 'VBP'), ('the', 'DT'), ('preferred', 'JJ'), ('choice', 'NN'), ('for', 'IN'), ('storing', 'VBG'), ('many', 'JJ'), ('kinds', 'NNS'), ('of', 'IN'), ('unstructured', 'JJ'), ('data', 'NNS')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "texts = 'Simple content searches can be performed on textual unstructured data. Traditional analytics tools are optimized for highly structured relational data, so they’re of little use for unstructured sources such as rich media, customer interactions, and social media data. Big Data and unstructured data often go together: IDC estimates that 90% of these extremely large datasets are unstructured. New tools have recently become available to analyze these and other unstructured sources. Powered by AI and machine learning, such platforms function at near real-time speed and educate themselves based on the patterns and insights they uncover.Unstructured types of data can actually have internal structural elements. They’re considered “unstructured” because their information doesn’t lend itself to the kind of table formatting required by a relational database. As noted earlier, unstructured data can be textual or non-textual (such as audio, video, and images), and generated by people or by machines. Non-relational databases such as MongoDB are the preferred choice for storing many kinds of unstructured data'\n",
    "\n",
    "sentences = nltk.sent_tokenize(texts)\n",
    "#print(sentences)\n",
    "for sentence in sentences:\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    #print(words)\n",
    "    tagged = nltk.pos_tag(words)\n",
    "    print(tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
